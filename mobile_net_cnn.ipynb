{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5276f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install kaggle --quiet\\n\\n# Step 2: Set up the Kaggle API credentials (ensure the \\'kaggle.json\\' is in the correct location)\\nimport os\\n# Make sure to place \\'kaggle.json\\' in the folder ~/.kaggle/\\nos.environ[\\'KAGGLE_CONFIG_DIR\\'] = \"~/.kaggle\"  # Update this path if needed\\n\\n# I had to do this because it wasn\\'t seeing my kaggle.json\\nos.environ[\\'KAGGLE_USERNAME\\'] = \\'\\'\\nos.environ[\\'KAGGLE_KEY\\'] = \\'\\'\\n\\n!kaggle competitions download -c rsna-pneumonia-detection-challenge\\n\\nimport zipfile\\nwith zipfile.ZipFile(\\'rsna-pneumonia-detection-challenge.zip\\', \\'r\\') as zip_ref:\\n    zip_ref.extractall(\\'rsna_data\\')\\n\\nimport os\\nos.listdir(\\'rsna_data\\')'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install kaggle --quiet\n",
    "\n",
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"~/.kaggle\"  # Update this path if needed\n",
    "\n",
    "# I had to do this because it wasn't seeing my kaggle.json\n",
    "os.environ['KAGGLE_USERNAME'] = ''\n",
    "os.environ['KAGGLE_KEY'] = ''\n",
    "\n",
    "!kaggle competitions download -c rsna-pneumonia-detection-challenge\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile('rsna-pneumonia-detection-challenge.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('rsna_data')\n",
    "\n",
    "import os\n",
    "os.listdir('rsna_data')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 20:32:02.793967: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-27 20:32:02.911695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745800322.966142  254264 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745800322.980750  254264 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-27 20:32:03.081503: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import ResNet50 \n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "\n",
    "data_dir = './rsna_data/stage_2_train_images'\n",
    "labels_df = pd.read_csv('./rsna_data/stage_2_train_labels.csv')\n",
    "\n",
    "def load_dicom_image(image_path):\n",
    "    dicom_data = pydicom.dcmread(image_path)\n",
    "    \n",
    "    image = dicom_data.pixel_array\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        image = np.stack([image] * 3, axis=-1)  # Convert grayscale to RGB\n",
    "    \n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    image = image / 255.0\n",
    "    \n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for idx, row in labels_df.iterrows():\n",
    "    image_path = os.path.join(data_dir, f'{row[\"patientId\"]}.dcm')\n",
    "    images.append(load_dicom_image(image_path))\n",
    "    labels.append(row[\"Target\"])\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165bb043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "'''train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")'''\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "validation_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988b855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745800441.245392  254264 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21458 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# 9. Build the model\\nmodel = models.Sequential([\\n    base_model,\\n    layers.GlobalAveragePooling2D(),\\n    layers.Dense(1, activation='sigmoid')  # Binary classification (pneumonia vs normal)\\n])\\n\\n# 10. Compile the model\\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\\n\\n# 11. Train the model\\nmodel.fit(train_generator, epochs=10, validation_data=validation_generator)\\n\\n# 12. Evaluate the model\\nloss, accuracy = model.evaluate(validation_generator)\\nprint(f'Validation Loss: {loss}')\\nprint(f'Validation Accuracy: {accuracy}')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "x = inputs\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "base_model.trainable = False\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Custom classification head\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a674e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342cbb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson_walsh/UTK/COSC523Project2/nlp/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745800446.582120  255037 service.cc:148] XLA service 0x7f1274050560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745800446.582259  255037 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-04-27 20:34:06.682154: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1745800447.201378  255037 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-04-27 20:34:07.964613: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6526_0', 112 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:08.089516: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9997', 60 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:08.101385: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9997', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:08.112551: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9997', 68 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:08.218588: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6526', 220 bytes spill stores, 576 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/756\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.5139 - loss: 0.7602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745800450.749581  255037 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m378/756\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6:02\u001b[0m 958ms/step - accuracy: 0.6445 - loss: 0.6683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 20:34:20.616602: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6526_0', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:20.701283: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6526', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:20.776576: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9997', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:20.783565: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9997', 20 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:20.827466: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9997', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:20.871072: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6526', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m504/756\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 728ms/step - accuracy: 0.6491 - loss: 0.6635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 20:34:29.332008: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702_0', 88 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:29.674891: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:35.264444: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695_0', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:35.339887: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:35.427212: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702_0', 352 bytes spill stores, 448 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:35.562151: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:35.563518: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:35.617909: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2025-04-27 20:34:35.699177: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 35ms/step - accuracy: 0.6562 - loss: 0.6565 - val_accuracy: 0.6839 - val_loss: 0.6282\n",
      "Epoch 2/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6887 - loss: 0.6221 - val_accuracy: 0.6839 - val_loss: 0.6242\n",
      "Epoch 3/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6852 - loss: 0.6175 - val_accuracy: 0.6839 - val_loss: 0.6042\n",
      "Epoch 4/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6827 - loss: 0.6018 - val_accuracy: 0.6981 - val_loss: 0.5702\n",
      "Epoch 5/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6897 - loss: 0.5755 - val_accuracy: 0.7110 - val_loss: 0.5514\n",
      "Epoch 6/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6973 - loss: 0.5674 - val_accuracy: 0.7086 - val_loss: 0.5402\n",
      "Epoch 7/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.7065 - loss: 0.5587 - val_accuracy: 0.7326 - val_loss: 0.5339\n",
      "Epoch 8/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7089 - loss: 0.5523 - val_accuracy: 0.6977 - val_loss: 0.5376\n",
      "Epoch 9/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7064 - loss: 0.5525 - val_accuracy: 0.7529 - val_loss: 0.5295\n",
      "Epoch 10/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7164 - loss: 0.5449 - val_accuracy: 0.7347 - val_loss: 0.5289\n",
      "Epoch 11/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7143 - loss: 0.5423 - val_accuracy: 0.6922 - val_loss: 0.5322\n",
      "Epoch 12/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7158 - loss: 0.5436 - val_accuracy: 0.7322 - val_loss: 0.5234\n",
      "Epoch 13/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7105 - loss: 0.5483 - val_accuracy: 0.7175 - val_loss: 0.5222\n",
      "Epoch 14/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.7113 - loss: 0.5439 - val_accuracy: 0.7590 - val_loss: 0.5166\n",
      "Epoch 15/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7156 - loss: 0.5419 - val_accuracy: 0.7602 - val_loss: 0.5211\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "# --- TRAINING ---\n",
    "early_stop = callbacks.EarlyStopping(patience=5, restore_best_weights=True, min_delta=0.001, monitor='accuracy', mode='max')\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5354b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_chest_pretune_resnet.keras\")\n",
    "from tensorflow.keras.models import load_model\n",
    "#model = load_model(\"cnn_chest_pretune.keras\")\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531dfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head_weights = [layer.get_weights() for layer in model.layers[-8:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be972a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    #metrics=[AUC(multi_label=True)]\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54eceeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, layer in enumerate(model.layers[-8:]):\n",
    "    layer.set_weights(classifier_head_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c252bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 20:37:55.004858: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18208', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m456/756\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:06\u001b[0m 821ms/step - accuracy: 0.7124 - loss: 0.8462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 20:44:27.320545: E external/local_xla/xla/service/slow_operation_alarm.cc:65] \n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_105407__.28411] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 67ms/step - accuracy: 0.7268 - loss: 0.7509 - val_accuracy: 0.4299 - val_loss: 1.0360 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.8326 - loss: 0.3800 - val_accuracy: 0.7474 - val_loss: 0.5225 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.8887 - loss: 0.2627 - val_accuracy: 0.8296 - val_loss: 0.4217 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.9561 - loss: 0.1240 - val_accuracy: 0.8248 - val_loss: 0.4877 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 46ms/step - accuracy: 0.9845 - loss: 0.0490 - val_accuracy: 0.7326 - val_loss: 1.0822 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m646/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1:05\u001b[0m 592ms/step - accuracy: 0.9873 - loss: 0.0344\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 47ms/step - accuracy: 0.9873 - loss: 0.0346 - val_accuracy: 0.8114 - val_loss: 0.8397 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.9913 - loss: 0.0247 - val_accuracy: 0.8278 - val_loss: 0.9097 - learning_rate: 5.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.8301 - val_loss: 0.9552 - learning_rate: 5.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m736/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 524ms/step - accuracy: 0.9957 - loss: 0.0144 \n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.9957 - loss: 0.0144 - val_accuracy: 0.8290 - val_loss: 1.0262 - learning_rate: 5.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.8445 - val_loss: 1.0249 - learning_rate: 2.5000e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 47ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.8412 - val_loss: 1.0918 - learning_rate: 2.5000e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m726/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m15s\u001b[0m 531ms/step - accuracy: 0.9988 - loss: 0.0033\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 47ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.8407 - val_loss: 1.1395 - learning_rate: 2.5000e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 47ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.8417 - val_loss: 1.1240 - learning_rate: 1.2500e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 46ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.8435 - val_loss: 1.1559 - learning_rate: 1.2500e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m697/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m32s\u001b[0m 551ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 515ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.8411 - val_loss: 1.1772 - learning_rate: 1.2500e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
