{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5da3da82",
      "metadata": {},
      "source": [
        "## Stage 1 Binary Classification ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e5276f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e5276f2",
        "outputId": "bb4081d9-c316-405f-9c72-9410a505747a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['stage_2_detailed_class_info.csv',\n",
              " 'stage_2_train_images',\n",
              " 'stage_2_sample_submission.csv',\n",
              " 'stage_2_train_labels.csv',\n",
              " 'GCP Credits Request Link - RSNA.txt',\n",
              " 'stage_2_test_images']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install kaggle --quiet\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"~/.kaggle\"  # Update this path if needed\n",
        "\n",
        "# I had to do this because it wasn't seeing my kaggle.json\n",
        "os.environ['KAGGLE_USERNAME'] = 'oscarjp'\n",
        "os.environ['KAGGLE_KEY'] = 'd371e4dda7ac9f5c9825e5075716d987'\n",
        "\n",
        "!kaggle competitions download -c rsna-pneumonia-detection-challenge\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('rsna-pneumonia-detection-challenge.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('rsna_data')\n",
        "\n",
        "import os\n",
        "os.listdir('rsna_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "I4lUlmW42jAf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4lUlmW42jAf",
        "outputId": "d3769349-668f-4d0f-8ede-16ac33b643e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-08 23:32:14.530849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746761534.584314     571 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746761534.600307     571 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1746761534.720524     571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1746761534.720570     571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1746761534.720571     571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1746761534.720572     571 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-05-08 23:32:14.735596: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "# !pip install pydicom\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d07b15f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available memory: 14.77 GB\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "print(f\"Available memory: {psutil.virtual_memory().available / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "89d24b02",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "854fd20a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utilizing this as a source to batch train\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/PyDataset\n",
        "\n",
        "class DICOMTrainBatch(tf.keras.utils.Sequence):\n",
        "    def __init__(self, df, data_dir, batch_size=32, img_size=(224, 224), shuffle=True):\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(df))\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_df = self.df.iloc[batch_indices]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            image_path = os.path.join(self.data_dir, f'{row[\"patientId\"]}.dcm')\n",
        "            image = load_dicom_image(image_path)\n",
        "            batch_images.append(image)\n",
        "            batch_labels.append(row[\"Target\"])\n",
        "\n",
        "        batch_images = np.array(batch_images) / 255.0\n",
        "        batch_labels = np.array(batch_labels)\n",
        "\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "aaf896bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = './rsna_data/stage_2_train_images'\n",
        "labels_df = pd.read_csv('./rsna_data/stage_2_train_labels.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3787cc64",
      "metadata": {
        "id": "3787cc64"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_dicom_image(image_path):\n",
        "    dicom_data = pydicom.dcmread(image_path)\n",
        "\n",
        "    image = dicom_data.pixel_array\n",
        "\n",
        "    if len(image.shape) == 2:\n",
        "        image = np.stack([image] * 3, axis=-1)  # Convert grayscale to RGB\n",
        "\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    image = image / 255.0\n",
        "\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    return image\n",
        "\n",
        "# images = []\n",
        "# labels = []\n",
        "# for idx, row in labels_df.iterrows():\n",
        "#     image_path = os.path.join(data_dir, f'{row[\"patientId\"]}.dcm')\n",
        "#     images.append(load_dicom_image(image_path))\n",
        "#     labels.append(row[\"Target\"])\n",
        "\n",
        "# images = np.array(images)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b8d39813",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5029c483",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821d38f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_generator = DICOMTrainBatch(train_df, data_dir, batch_size=32)\n",
        "validation_generator = DICOMTrainBatch(val_df, data_dir, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "165bb043",
      "metadata": {
        "id": "165bb043"
      },
      "outputs": [],
      "source": [
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# '''train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True\n",
        "# )'''\n",
        "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "# validation_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f988b855",
      "metadata": {
        "id": "f988b855"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1746842975.916008     555 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "x = inputs\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "x = base_model(x, training=False)\n",
        "\n",
        "# Custom classification head\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1a674e29",
      "metadata": {
        "id": "1a674e29"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "\tmetrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342cbb99",
      "metadata": {
        "id": "342cbb99",
        "outputId": "47565acc-af95-4217-cb4e-72f6c95c1b49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1746625703.171531    9302 service.cc:152] XLA service 0x7f52d404f910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1746625703.171571    9302 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
            "2025-05-07 09:48:23.359736: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1746625704.171526    9302 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-05-07 09:48:25.431931: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 204 bytes spill stores, 204 bytes spill loads\n",
            "\n",
            "2025-05-07 09:48:25.609538: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9078', 36 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "2025-05-07 09:48:25.618595: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837_0', 396 bytes spill stores, 2300 bytes spill loads\n",
            "\n",
            "2025-05-07 09:48:25.750028: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9078', 20 bytes spill stores, 20 bytes spill loads\n",
            "\n",
            "2025-05-07 09:48:25.975302: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 3940 bytes spill stores, 3920 bytes spill loads\n",
            "\n",
            "2025-05-07 09:48:26.020865: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 992 bytes spill stores, 992 bytes spill loads\n",
            "\n",
            "2025-05-07 09:48:26.027768: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9078', 32 bytes spill stores, 32 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  2/756\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 54ms/step - accuracy: 0.5469 - loss: 0.8321   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1746625709.682037    9302 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m525/756\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 428ms/step - accuracy: 0.6630 - loss: 0.6563"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 09:52:16.142318: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-05-07 09:52:16.360726: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 220 bytes spill stores, 220 bytes spill loads\n",
            "\n",
            "2025-05-07 09:52:16.479920: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9078', 28 bytes spill stores, 32 bytes spill loads\n",
            "\n",
            "2025-05-07 09:52:16.487375: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9078', 20 bytes spill stores, 20 bytes spill loads\n",
            "\n",
            "2025-05-07 09:52:16.848268: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 4384 bytes spill stores, 4228 bytes spill loads\n",
            "\n",
            "2025-05-07 09:52:16.856251: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "2025-05-07 09:52:16.938622: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5837', 1008 bytes spill stores, 1008 bytes spill loads\n",
            "\n",
            "2025-05-07 09:52:16.955042: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_9078', 32 bytes spill stores, 32 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.6668 - loss: 0.6511"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 09:53:59.931710: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702_0', 468 bytes spill stores, 1028 bytes spill loads\n",
            "\n",
            "2025-05-07 09:54:00.197755: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 488 bytes spill stores, 488 bytes spill loads\n",
            "\n",
            "2025-05-07 09:54:00.209512: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 80 bytes spill stores, 144 bytes spill loads\n",
            "\n",
            "2025-05-07 09:54:00.210110: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 608 bytes spill stores, 608 bytes spill loads\n",
            "\n",
            "2025-05-07 09:54:00.269813: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 832 bytes spill stores, 832 bytes spill loads\n",
            "\n",
            "2025-05-07 09:54:00.357006: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1709_0', 44 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "2025-05-07 09:54:00.594082: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1709', 484 bytes spill stores, 484 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:21.733352: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:22.143282: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695', 220 bytes spill stores, 220 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:22.356366: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:22.554980: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 612 bytes spill stores, 612 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:22.675483: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 492 bytes spill stores, 492 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:22.778724: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695', 4384 bytes spill stores, 4228 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:22.916348: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702_0', 592 bytes spill stores, 1236 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:23.165504: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:23.258361: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1695', 1008 bytes spill stores, 1008 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:23.321305: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 212 bytes spill stores, 244 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:23.366191: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1709_0', 36 bytes spill stores, 36 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:23.483363: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1709', 488 bytes spill stores, 488 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:23.613270: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1702', 820 bytes spill stores, 820 bytes spill loads\n",
            "\n",
            "2025-05-07 09:55:33.441134: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv %cudnn-conv-bias-activation.170 = (f32[30,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,256,56,56]{3,2,1,0} %bitcast.5125, f32[512,256,1,1]{3,2,1,0} %bitcast.5094, f32[512]{0} %bitcast.5096), window={size=1x1 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/resnet50_1/conv3_block1_0_conv_1/convolution\" source_file=\"/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2025-05-07 09:55:33.453459: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 8.968638354s\n",
            "Trying algorithm eng20{k2=2,k4=1,k5=0,k6=0,k7=0,k19=0} for conv %cudnn-conv-bias-activation.170 = (f32[30,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,256,56,56]{3,2,1,0} %bitcast.5125, f32[512,256,1,1]{3,2,1,0} %bitcast.5094, f32[512]{0} %bitcast.5096), window={size=1x1 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/resnet50_1/conv3_block1_0_conv_1/convolution\" source_file=\"/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 552ms/step - accuracy: 0.6668 - loss: 0.6511 - val_accuracy: 0.6839 - val_loss: 0.6314\n",
            "Epoch 2/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 499ms/step - accuracy: 0.6821 - loss: 0.6275 - val_accuracy: 0.6839 - val_loss: 0.6221\n",
            "Epoch 3/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 502ms/step - accuracy: 0.6827 - loss: 0.6153 - val_accuracy: 0.6886 - val_loss: 0.5869\n",
            "Epoch 4/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 518ms/step - accuracy: 0.6758 - loss: 0.5935 - val_accuracy: 0.6839 - val_loss: 0.5711\n",
            "Epoch 5/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 513ms/step - accuracy: 0.6842 - loss: 0.5794 - val_accuracy: 0.6867 - val_loss: 0.5517\n",
            "Epoch 6/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 502ms/step - accuracy: 0.6936 - loss: 0.5683 - val_accuracy: 0.6851 - val_loss: 0.5552\n",
            "Epoch 7/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 494ms/step - accuracy: 0.6948 - loss: 0.5623 - val_accuracy: 0.7478 - val_loss: 0.5402\n",
            "Epoch 8/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 492ms/step - accuracy: 0.6972 - loss: 0.5578 - val_accuracy: 0.6882 - val_loss: 0.5424\n",
            "Epoch 9/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 504ms/step - accuracy: 0.7094 - loss: 0.5543 - val_accuracy: 0.7135 - val_loss: 0.5483\n",
            "Epoch 10/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 494ms/step - accuracy: 0.7160 - loss: 0.5476 - val_accuracy: 0.7307 - val_loss: 0.5248\n",
            "Epoch 11/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 491ms/step - accuracy: 0.7142 - loss: 0.5469 - val_accuracy: 0.7317 - val_loss: 0.5222\n",
            "Epoch 12/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 493ms/step - accuracy: 0.7192 - loss: 0.5396 - val_accuracy: 0.7436 - val_loss: 0.5203\n",
            "Epoch 13/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 494ms/step - accuracy: 0.7222 - loss: 0.5397 - val_accuracy: 0.6929 - val_loss: 0.5301\n",
            "Epoch 14/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 490ms/step - accuracy: 0.7274 - loss: 0.5346 - val_accuracy: 0.7550 - val_loss: 0.5297\n",
            "Epoch 15/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 493ms/step - accuracy: 0.7162 - loss: 0.5435 - val_accuracy: 0.7127 - val_loss: 0.5382\n",
            "Epoch 16/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 497ms/step - accuracy: 0.7188 - loss: 0.5405 - val_accuracy: 0.7211 - val_loss: 0.5317\n",
            "Epoch 17/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 489ms/step - accuracy: 0.7001 - loss: 0.5439 - val_accuracy: 0.7119 - val_loss: 0.5231\n",
            "Epoch 18/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 493ms/step - accuracy: 0.7121 - loss: 0.5424 - val_accuracy: 0.6948 - val_loss: 0.5315\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import callbacks\n",
        "# --- TRAINING ---\n",
        "early_stop = callbacks.EarlyStopping(patience=5, restore_best_weights=True, min_delta=0.001, monitor='accuracy', mode='max')\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5354b010",
      "metadata": {
        "id": "5354b010"
      },
      "outputs": [],
      "source": [
        "# model.save(\"cnn_chest_pretune_resnet.keras\")\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"cnn_chest_pretune_resnet.keras\")\n",
        "# base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "531dfd33",
      "metadata": {
        "id": "531dfd33"
      },
      "outputs": [],
      "source": [
        "classifier_head_weights = [layer.get_weights() for layer in model.layers[-8:]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "be972a52",
      "metadata": {
        "id": "be972a52"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    #metrics=[AUC(multi_label=True)]\n",
        "\tmetrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "54eceeec",
      "metadata": {
        "id": "54eceeec"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i, layer in enumerate(model.layers[-8:]):\n",
        "    layer.set_weights(classifier_head_weights[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "51c252bb",
      "metadata": {
        "id": "51c252bb",
        "outputId": "fc11a904-6c71-45b1-e742-cf855472d517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 12:10:09.962113: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_17501_0', 204 bytes spill stores, 420 bytes spill loads\n",
            "\n",
            "2025-05-07 12:10:10.078705: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_17501', 84 bytes spill stores, 84 bytes spill loads\n",
            "\n",
            "2025-05-07 12:10:10.140549: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_17501', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-05-07 12:10:20.693199: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng34{k2=0,k12=-1,k13=2,k14=3,k15=0,k17=128,k18=1,k23=0} for conv %cudnn-conv-bw-input.34 = (f32[32,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0} %bitcast.69806, f32[256,512,1,1]{3,2,1,0} %bitcast.69743), window={size=1x1 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/functional_1/resnet50_1/conv4_block1_1_conv_1/convolution/Conv2DBackpropInput\" source_file=\"/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2025-05-07 12:10:20.698221: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 8.76018281s\n",
            "Trying algorithm eng34{k2=0,k12=-1,k13=2,k14=3,k15=0,k17=128,k18=1,k23=0} for conv %cudnn-conv-bw-input.34 = (f32[32,512,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,14,14]{3,2,1,0} %bitcast.69806, f32[256,512,1,1]{3,2,1,0} %bitcast.69743), window={size=1x1 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/functional_1/resnet50_1/conv4_block1_1_conv_1/convolution/Conv2DBackpropInput\" source_file=\"/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m558/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 424ms/step - accuracy: 0.7153 - loss: 0.9195"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-07 12:14:34.001522: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_17501', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-05-07 12:14:34.099187: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_17501_0', 204 bytes spill stores, 444 bytes spill loads\n",
            "\n",
            "2025-05-07 12:14:34.160879: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_17501', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "2025-05-07 12:14:46.194922: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.56 = (f32[256,64,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,64,56,56]{3,2,1,0} %bitcast.65377, f32[21,256,56,56]{3,2,1,0} %bitcast.65431), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/resnet50_1/conv2_block1_3_conv_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2025-05-07 12:14:46.213116: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 8.769622793s\n",
            "Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.56 = (f32[256,64,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,64,56,56]{3,2,1,0} %bitcast.65377, f32[21,256,56,56]{3,2,1,0} %bitcast.65431), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/resnet50_1/conv2_block1_3_conv_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 546ms/step - accuracy: 0.7230 - loss: 0.8464 - val_accuracy: 0.4305 - val_loss: 1.4420 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 493ms/step - accuracy: 0.8148 - loss: 0.3984 - val_accuracy: 0.7668 - val_loss: 0.4831 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 493ms/step - accuracy: 0.8663 - loss: 0.2972 - val_accuracy: 0.8028 - val_loss: 0.4659 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 495ms/step - accuracy: 0.9352 - loss: 0.1651 - val_accuracy: 0.8141 - val_loss: 0.5409 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 495ms/step - accuracy: 0.9798 - loss: 0.0618 - val_accuracy: 0.8338 - val_loss: 0.6496 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m751/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.9886 - loss: 0.0340\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 496ms/step - accuracy: 0.9886 - loss: 0.0340 - val_accuracy: 0.7964 - val_loss: 0.9035 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 495ms/step - accuracy: 0.9916 - loss: 0.0259 - val_accuracy: 0.8293 - val_loss: 0.8981 - learning_rate: 5.0000e-06\n",
            "Epoch 8/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 494ms/step - accuracy: 0.9962 - loss: 0.0111 - val_accuracy: 0.7984 - val_loss: 0.9033 - learning_rate: 5.0000e-06\n",
            "Epoch 9/50\n",
            "\u001b[1m752/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 406ms/step - accuracy: 0.9979 - loss: 0.0076\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 492ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 0.8399 - val_loss: 1.1019 - learning_rate: 5.0000e-06\n",
            "Epoch 10/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 495ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.8387 - val_loss: 1.1428 - learning_rate: 2.5000e-06\n",
            "Epoch 11/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 492ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.8492 - val_loss: 1.1045 - learning_rate: 2.5000e-06\n",
            "Epoch 12/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.9987 - loss: 0.0041\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 500ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 0.8457 - val_loss: 1.1449 - learning_rate: 2.5000e-06\n",
            "Epoch 13/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 492ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.8478 - val_loss: 1.1782 - learning_rate: 1.2500e-06\n",
            "Epoch 14/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 496ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.8427 - val_loss: 1.1925 - learning_rate: 1.2500e-06\n",
            "Epoch 15/50\n",
            "\u001b[1m743/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 411ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 498ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.8366 - val_loss: 1.2517 - learning_rate: 1.2500e-06\n",
            "Epoch 16/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 497ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.8495 - val_loss: 1.1971 - learning_rate: 6.2500e-07\n",
            "Epoch 17/50\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 488ms/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.8397 - val_loss: 1.2253 - learning_rate: 6.2500e-07\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee3ef0e",
      "metadata": {},
      "source": [
        "## Stage 2 Bounding Boxes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "590d4250",
      "metadata": {},
      "source": [
        "### Some data pre-processing -> only include target==1 since target==0 has no dimensional values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c6015ae5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patientId</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>264.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>562.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
              "      <td>323.0</td>\n",
              "      <td>577.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
              "      <td>695.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>00aecb01-a116-45a2-956c-08d2fa55433f</td>\n",
              "      <td>288.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               patientId      x      y  width  height  Target\n",
              "4   00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1\n",
              "5   00436515-870c-4b36-a041-de91049b9ab4  562.0  152.0  256.0   453.0       1\n",
              "8   00704310-78a8-4b38-8475-49f4573b2dbb  323.0  577.0  160.0   104.0       1\n",
              "9   00704310-78a8-4b38-8475-49f4573b2dbb  695.0  575.0  162.0   137.0       1\n",
              "14  00aecb01-a116-45a2-956c-08d2fa55433f  288.0  322.0   94.0   135.0       1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bounding_boxes_df = labels_df[(labels_df[\"Target\"] == 1) & labels_df[\"x\"].notna()].copy()\n",
        "\n",
        "bounding_boxes_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "69653100",
      "metadata": {},
      "outputs": [],
      "source": [
        "bounding_boxes_df['norm_x'] = bounding_boxes_df['x']/1024\n",
        "bounding_boxes_df['norm_y'] = bounding_boxes_df['y']/1024\n",
        "bounding_boxes_df['norm_width_x'] = (bounding_boxes_df['x'] + bounding_boxes_df['width'])/1024\n",
        "bounding_boxes_df['norm_height_y'] = (bounding_boxes_df['y'] + bounding_boxes_df['height'])/1024\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2f423603",
      "metadata": {},
      "outputs": [],
      "source": [
        "bb_train_df, bb_val_df = train_test_split(bounding_boxes_df, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "cc483290",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utilizing this as a source to batch train\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/PyDataset\n",
        "\n",
        "class DICOMTrainBatchCoordinates(tf.keras.utils.Sequence):\n",
        "    def __init__(self, df, data_dir, batch_size=32, img_size=(224, 224), shuffle=True):\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(df))\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_df = self.df.iloc[batch_indices]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_bb = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            image_path = os.path.join(self.data_dir, f'{row[\"patientId\"]}.dcm')\n",
        "            image = load_dicom_image(image_path)\n",
        "            batch_images.append(image)\n",
        "            batch_bb.append([row['norm_x'], row['norm_y'], row['norm_width_x'], row['norm_height_y']])\n",
        "\n",
        "        batch_images = np.array(batch_images) / 255.0\n",
        "        batch_bb = np.array(batch_bb)\n",
        "\n",
        "        return batch_images, batch_bb\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7daca0bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "bounding_box_train_batch = DICOMTrainBatchCoordinates(bb_train_df, data_dir)\n",
        "bounding_box_val_batch = DICOMTrainBatchCoordinates(bb_val_df, data_dir, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "87215c7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "\n",
        "base_model = MobileNetV2(include_top=False,input_shape=(224,224,3), weights='imagenet')\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "outputs = Dense(4, activation='sigmoid')(x)\n",
        "\n",
        "bounding_box_model = tf.keras.Model(inputs=base_model.input,outputs=outputs)\n",
        "bounding_box_model.compile(optimizer='adam',loss='mean_squared_error', metrics=['accuracy','mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d022b0a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.5715 - loss: 0.0381 - mae: 0.1606"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ojp/projects/tf217/tf217/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "2025-05-09 23:02:49.877279: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1207', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-05-09 23:02:49.899410: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1207', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-05-09 23:03:14.573107: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1200', 220 bytes spill stores, 220 bytes spill loads\n",
            "\n",
            "2025-05-09 23:03:14.657933: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1200_0', 444 bytes spill stores, 1384 bytes spill loads\n",
            "\n",
            "2025-05-09 23:03:14.913411: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1200', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "2025-05-09 23:03:15.010592: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1200', 5524 bytes spill stores, 5564 bytes spill loads\n",
            "\n",
            "2025-05-09 23:03:15.121870: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1200', 5388 bytes spill stores, 5392 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 555ms/step - accuracy: 0.5717 - loss: 0.0380 - mae: 0.1605 - val_accuracy: 0.4097 - val_loss: 0.1233 - val_mae: 0.2963\n",
            "Epoch 2/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 476ms/step - accuracy: 0.6328 - loss: 0.0249 - mae: 0.1325 - val_accuracy: 0.5081 - val_loss: 0.0674 - val_mae: 0.2059\n",
            "Epoch 3/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 471ms/step - accuracy: 0.6430 - loss: 0.0238 - mae: 0.1285 - val_accuracy: 0.5924 - val_loss: 0.0670 - val_mae: 0.2200\n",
            "Epoch 4/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 475ms/step - accuracy: 0.6484 - loss: 0.0231 - mae: 0.1263 - val_accuracy: 0.5777 - val_loss: 0.0412 - val_mae: 0.1720\n",
            "Epoch 5/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 472ms/step - accuracy: 0.6549 - loss: 0.0228 - mae: 0.1249 - val_accuracy: 0.5908 - val_loss: 0.0439 - val_mae: 0.1794\n",
            "Epoch 6/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 475ms/step - accuracy: 0.6458 - loss: 0.0241 - mae: 0.1299 - val_accuracy: 0.5924 - val_loss: 0.0545 - val_mae: 0.2001\n",
            "Epoch 7/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 472ms/step - accuracy: 0.6553 - loss: 0.0224 - mae: 0.1237 - val_accuracy: 0.6159 - val_loss: 0.0410 - val_mae: 0.1600\n",
            "Epoch 8/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 474ms/step - accuracy: 0.6584 - loss: 0.0222 - mae: 0.1231 - val_accuracy: 0.6206 - val_loss: 0.0276 - val_mae: 0.1371\n",
            "Epoch 9/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 474ms/step - accuracy: 0.6475 - loss: 0.0221 - mae: 0.1216 - val_accuracy: 0.6102 - val_loss: 0.0288 - val_mae: 0.1402\n",
            "Epoch 10/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 475ms/step - accuracy: 0.6585 - loss: 0.0214 - mae: 0.1196 - val_accuracy: 0.6033 - val_loss: 0.0323 - val_mae: 0.1499\n",
            "Epoch 11/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 476ms/step - accuracy: 0.6652 - loss: 0.0211 - mae: 0.1189 - val_accuracy: 0.6096 - val_loss: 0.0301 - val_mae: 0.1468\n",
            "Epoch 12/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 475ms/step - accuracy: 0.6815 - loss: 0.0205 - mae: 0.1167 - val_accuracy: 0.5829 - val_loss: 0.0309 - val_mae: 0.1500\n",
            "Epoch 13/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 474ms/step - accuracy: 0.6603 - loss: 0.0204 - mae: 0.1168 - val_accuracy: 0.6065 - val_loss: 0.0288 - val_mae: 0.1400\n",
            "Epoch 14/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 475ms/step - accuracy: 0.6815 - loss: 0.0204 - mae: 0.1161 - val_accuracy: 0.5583 - val_loss: 0.0319 - val_mae: 0.1485\n",
            "Epoch 15/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 473ms/step - accuracy: 0.6804 - loss: 0.0203 - mae: 0.1154 - val_accuracy: 0.5709 - val_loss: 0.0307 - val_mae: 0.1459\n",
            "Epoch 16/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 478ms/step - accuracy: 0.6988 - loss: 0.0196 - mae: 0.1128 - val_accuracy: 0.5474 - val_loss: 0.0367 - val_mae: 0.1596\n",
            "Epoch 17/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 472ms/step - accuracy: 0.6731 - loss: 0.0197 - mae: 0.1131 - val_accuracy: 0.5400 - val_loss: 0.0327 - val_mae: 0.1505\n",
            "Epoch 18/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 476ms/step - accuracy: 0.6784 - loss: 0.0193 - mae: 0.1116 - val_accuracy: 0.5678 - val_loss: 0.0326 - val_mae: 0.1487\n",
            "Epoch 19/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 474ms/step - accuracy: 0.6800 - loss: 0.0193 - mae: 0.1116 - val_accuracy: 0.5793 - val_loss: 0.0299 - val_mae: 0.1484\n",
            "Epoch 20/20\n",
            "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 477ms/step - accuracy: 0.6891 - loss: 0.0193 - mae: 0.1119 - val_accuracy: 0.5720 - val_loss: 0.0323 - val_mae: 0.1531\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fdca44eaff0>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bounding_box_model.fit(bounding_box_train_batch, validation_data=bounding_box_val_batch,epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e26bcf3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "bounding_box_model.save(\"cnn_chest_pretune_bb.keras\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6fb203",
      "metadata": {},
      "source": [
        "## Building a 2 stage Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc9ed058",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pydicom\n",
        "binary_class_model = load_model(\"cnn_chest_pretune_resnet.keras\")\n",
        "bounding_box_model = load_model(\"cnn_chest_pretune_bb.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "47a63de3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prep_image(path):\n",
        "    img = load_dicom_image(path)\n",
        "    img = img / 255.0\n",
        "    return img[np.newaxis,...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4f6fa55d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def class_bounding_pipeline(dicom_img, prob_thres=0.4):\n",
        "    test_img = prep_image(dicom_img)\n",
        "\n",
        "    prob_class = binary_class_model.predict(test_img)[0][0]\n",
        "    print(f\"Probability of pneumonia: {prob_class:.2f}\")\n",
        "\n",
        "    if prob_class >= prob_thres:\n",
        "        bb_coor = bounding_box_model.predict(test_img)[0]\n",
        "        x1,y1,x2,y2 = (bb_coor * 1024).astype(int)\n",
        "        print(\"Predicted location of penumonia: \", (x1,y1,x2,y2))\n",
        "    \n",
        "        read_img = load_dicom_image(dicom_img)\n",
        "        plt.imshow(read_img, cmap='gray')\n",
        "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='red', lw=2, fill=False))\n",
        "        plt.title(f\"Pneumonia Detected (p={prob_class:.2f})\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        return prob_class, (x1,y1,x2,y2)\n",
        "    else:\n",
        "        print(\"No pneumonia detected.\")\n",
        "        return prob_class, None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "753497ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1746884937.952009    1094 service.cc:152] XLA service 0x7f7548003aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1746884937.952042    1094 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
            "2025-05-10 09:48:58.014137: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1746884938.390663    1094 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "Probability of pneumonia: 0.26\n",
            "No pneumonia detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1746884940.330619    1094 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(np.float32(0.25548166), None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_bounding_pipeline(\"./rsna_data/stage_2_test_images/0000a175-0e68-4ca4-b1af-167204a7e0bc.dcm\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf217",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
